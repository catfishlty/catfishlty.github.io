<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Catfish</title><link>https://www.catfish.top/post/</link><description>Recent content in Posts on Catfish</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Mon, 09 Aug 2021 10:33:00 +0800</lastBuildDate><atom:link href="https://www.catfish.top/post/index.xml" rel="self" type="application/rss+xml"/><item><title>JVM 垃圾回收器 - G1</title><link>https://www.catfish.top/p/jvm-gc-g1-1/</link><pubDate>Mon, 09 Aug 2021 10:33:00 +0800</pubDate><guid>https://www.catfish.top/p/jvm-gc-g1-1/</guid><description>G1 GC G1 GC，全称 Garbage-First Garbage Collector，通过 -XX:+UseG1GC参数来启用。 它是专门针对以下应用场景设计的:
像 CMS 收集器一样，能与应用程序线程并发执行。 整理空闲空间更快。 需要 GC 停顿时间更好预测。 不希望牺牲大量的吞吐性能。 不需要更大的 Java 堆内存。 G1 收集器的设计目标是取代 CMS 收集器，它同 CMS 相比，在以下方面表现的更出色： G1 是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。 G1 的 Stop The World(STW) 更可控，G1 在停顿时间上添加了预测机制，用户可以指定期望停顿时间。
重要概念 Region 传统的 GC 收集器将连续的内存空间划分为新生代、老年代和永久代（JDK 8 去除了永久代，引入了元空间 Metaspace ），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示：
JDK 8 Memory Structure
而 G1 的各代存储地址是不连续的，每一代都使用了 n 个不连续的大小相同的 Region，每个* Region* 占有一块连续的虚拟内存地址。如下图所示：
JDK 8 G1 GC Memory Structure
G1 的堆结构就是把一整块内存区域切分成多个固定大小的块，每一块被称为一个 Region 。在JVM在启动时来决定每个小块，也就是 Region 的大小。 JVM一般是把一整块堆切分成大约 2000 个 Region 。每个小 Region 从 1 到 32Mb 不等，且是 2 的指数，如果不设定，那么G1会根据Heap大小自动决定。这些 Region 最后又被分别标记为Eden , Survivor 和 Old 。这里的 Eden ， Survivor 和old已经是一个标签，也就是说只是一个逻辑表示，不是物理表示。O表示老生代（ Old ），E表示 Eden ，S表示 Survivor 。为了明了，我们分别用三种不同的颜色区分。存活下来的对象就被虚拟机从一个 Region 里被移动到另一个中。这些小块 Region 的回收是并行回收的，期间其他的应用线程照常工作。和以往的回收器一样， G1 中也有 Eden , Survivor , Old 。在这三个之外，还增加了第四种类型，叫 Humongous 。这个单词翻译过来就是“堆积如山”的意思。这个类型主要是用来存储那些比标准块大50%，甚至更大的那些对象。这些大对象被保存到一整块连续的区域。这个堆积如山区就是堆里没有被使用的区域。记住一点： G1 不是像老一辈的那些垃圾回收器一样要求每一代的块是连续的，在 G1 中可以不是连续的。</description></item><item><title>Kubernetes进阶（一）</title><link>https://www.catfish.top/p/k8s-inter-1/</link><pubDate>Mon, 26 Jul 2021 17:00:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-inter-1/</guid><description>Kubernetes官网文档：使用Kubernetes对象
本系列教程是在 Kubernetes初探 系列教程基础上，通过对官方文档的阅读完善各个重要知识点。
本章节将基于官网文档简化文章理解难度。
理解 Kubernetes 对象 在 Kubernetes 中，Kubernetes 对象 是持久化的实体。 Kubernetes 使用这些实体去表示整个集群的状态。它们描述了如下信息：
哪些容器化应用在运行（以及在哪些节点上） 可以被应用使用的资源 关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略 操作 Kubernetes 对象 —— 无论是创建、修改，或者删除 —— 需要使用 Kubernetes API。 比如，当使用 kubectl 命令行接口时，CLI 会执行必要的 Kubernetes API 调用， 也可以在程序中使用 客户端库直接调用 Kubernetes API。
对象规约（Spec）与状态（Status） 几乎每个 Kubernetes 对象包含两个嵌套的对象字段，它们负责管理对象的配置： 对象 spec（规约） 和 对象 status（状态） 。 对于具有 spec 的对象，你必须在创建对象时设置其内容，描述你希望对象所具有的特征： 期望状态（Desired State） 。
status 描述了对象的 当前状态（Current State），它是由 Kubernetes 系统和组件 设置并更新的。在任何时刻，Kubernetes 控制平面 都一直积极地管理着对象的实际状态，以使之与期望状态相匹配。
描述 Kubernetes 对象 创建 Kubernetes 对象时，必须提供对象的规约，用来描述该对象的期望状态， 以及关于对象的一些基本信息（例如名称）。</description></item><item><title>Kubernetes初探（十一）</title><link>https://www.catfish.top/p/k8s-basic-11/</link><pubDate>Fri, 23 Jul 2021 14:54:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-11/</guid><description>Katacoda在线课：Helm Package Manager
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
这个场景教你如何使用 Kubernetes 的包管理器 Helm 来部署 Redis。 Helm 简化了服务发现和部署到 Kubernetes 集群的步骤。。
&amp;ldquo;Helm is the best way to find, share, and use software built for Kubernetes.&amp;quot;
Helm 是查找、共享和使用为 Kubernetes 构建的软件的最佳方式
更多细节可以前往官网：http://www.helm.sh/
安装 Helm Helm 是一个单独的二进制文件，用于管理将 Charts 部署到 Kubernetes。 Chart 是 kubernetes 应用的一个打包单元。Helm 可以从 https://github.com/kubernetes/helm/releases 下载。
controlplane $ curl -LO https://storage.googleapis.com/kubernetes-helm/helm-v2.8.2-linux-amd64.tar.gz % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 14.</description></item><item><title>Kubernetes初探（十）</title><link>https://www.catfish.top/p/k8s-basic-10/</link><pubDate>Fri, 23 Jul 2021 14:54:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-10/</guid><description>Katacoda在线课：Use Kubernetes To Manage Secrets And Passwords
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
在此场景中，您将了解如何使用 Kubernetes 管理 Secrets 。 Kubernetes 允许您创建通过环境变量或作为卷挂载到 Pod 的 Secrets 。
只允许 Secrets （例如 SSL 证书或密码）通过基础架构团队以安全的方式进行管理，而不是将密码存储在应用程序的部署工件中。
启动 Kubernetes 首先，我们需要启动一个 Kubernetes 集群。
执行以下命令启动集群组件并下载 Kubectl CLI。
controlplane $ launch.sh Waiting for Kubernetes to start... Kubernetes started 创建 Secrets Kubernetes 要求将 Secrets 编码为 Base64 的字符串。
使用命令行工具，我们可以创建 Base64 字符串并将它们存储为变量在文件中使用。
controlplane $ username=$(echo -n &amp;#34;admin&amp;#34; | base64) controlplane $ password=$(echo -n &amp;#34;a62fjbd37942dcs&amp;#34; | base64) Secrets 是使用 YAML 定义的。下面我们将使用上面定义的变量，并为它们提供我们的应用程序可以使用的标签。这将创建一个可以通过名称访问的键/值秘密的集合。</description></item><item><title>Kubernetes初探（九）</title><link>https://www.catfish.top/p/k8s-basic-9/</link><pubDate>Fri, 23 Jul 2021 14:23:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-9/</guid><description>Katacoda在线课：Running Stateful Services on Kubernetes
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
部署 NFS 服务器 NFS 是一种允许节点通过网络读 / 写数据的协议。该协议的工作原理是让主节点运行 NFS 守护程序并存储数据。此主节点使某些目录可通过网络使用。
客户端访问通过驱动器挂载共享的主服务器。从应用程序的角度来看，它们正在写入本地磁盘。在背后，NFS 协议将其写入主服务器。
任务 在此场景中，出于演示和学习目的，NFS 服务器的角色由自定义容器处理。容器通过 NFS 提供目录并将数据存储在容器内。在生产环境中，建议配置专用的 NFS Server。
使用 docker run -d --net=host \ --privileged --name nfs-server \ katacoda/contained-nfs-server:centos7 \ /exports/data-0001 /exports/data-0002 命令启动 NFS 服务器
controlplane $ docker run -d --net=host \ &amp;gt; --privileged --name nfs-server \ &amp;gt; katacoda/contained-nfs-server:centos7 \ &amp;gt; /exports/data-0001 /exports/data-0002 Unable to find image &amp;#39;katacoda/contained-nfs-server:centos7&amp;#39; locally centos7: Pulling from katacoda/contained-nfs-server 8d30e94188e7: Pull complete 2b2b27f1f462: Pull complete 133e63cf95fe: Pull complete Digest: sha256:5f2ea4737fe27f26be5b5cabaa23e24180079a4dce8d5db235492ec48c5552d1 Status: Downloaded newer image for katacoda/contained-nfs-server:centos7 65699a0a96bfc489fe2141a815ef12b03917f9bb667340b1be68dfe838d14bf3 NFS 服务器公开两个目录，data-0001 和 data-0002。在接下来的步骤中，这将用于存储数据。</description></item><item><title>Kubernetes初探（八）</title><link>https://www.catfish.top/p/k8s-basic-8/</link><pubDate>Fri, 23 Jul 2021 13:07:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-8/</guid><description>Katacoda在线课：Liveness and Readiness Healthchecks
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
在此场景中，您将了解 Kubernetes 如何使用 Readiness and Liveness Probes 检查容器运行状况。
Readiness Probe 检查应用是否准备好开始处理流量。此探针解决了容器已启动的问题，但该进程仍在预热和配置自身，这意味着它尚未准备好接收流量。
Liveness Probe 确保应用程序健康并能够处理请求。
启动集群 首先，我们需要启动一个 Kubernetes 集群。
执行以下命令启动集群组件并下载 Kubectl CLI
controlplane $ launch.sh Waiting for Kubernetes to start... Kubernetes started 集群启动后，使用 kubectl apply -f deploy.yaml 部署演示应用程序。
deploy.yaml
kind:ListapiVersion:v1items:- kind:ReplicationControllerapiVersion:v1metadata:name:frontendlabels:name:frontendspec:replicas:1selector:name:frontendtemplate:metadata:labels:name:frontendspec:containers:- name:frontendimage:katacoda/docker-http-server:healthreadinessProbe:httpGet:path:/port:80initialDelaySeconds:1timeoutSeconds:1livenessProbe:httpGet:path:/port:80initialDelaySeconds:1timeoutSeconds:1- kind:ReplicationControllerapiVersion:v1metadata:name:bad-frontendlabels:name:bad-frontendspec:replicas:1selector:name:bad-frontendtemplate:metadata:labels:name:bad-frontendspec:containers:- name:bad-frontendimage:katacoda/docker-http-server:unhealthyreadinessProbe:httpGet:path:/port:80initialDelaySeconds:1timeoutSeconds:1livenessProbe:httpGet:path:/port:80initialDelaySeconds:1timeoutSeconds:1- kind:ServiceapiVersion:v1metadata:labels:app:frontendkubernetes.io/cluster-service:&amp;#34;true&amp;#34;name:frontendspec:type:NodePortports:- port:80nodePort:30080selector:app:frontendcontrolplane $ kubectl apply -f deploy.yaml replicationcontroller/frontend created replicationcontroller/bad-frontend created service/frontend created Readiness Probe 在部署集群时，还部署了两个 Pod 来演示健康检查。您可以使用 cat deploy.</description></item><item><title>Kubernetes初探（七）</title><link>https://www.catfish.top/p/k8s-basic-7/</link><pubDate>Tue, 20 Jul 2021 15:30:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-7/</guid><description>Katacoda在线课：Create Ingress Routing
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
Kubernetes 具有先进的网络功能，允许 Pod 和 Service 在集群网络内部进行通信。 Ingress 开启了到集群的入站连接，允许外部流量到达正确的 Pod。
Ingress 能够提供外部可访问的 URL、负载平衡流量、终止 SSL、为 Kubernetes 集群提供基于名称的虚拟主机。
在此场景中，您将学习如何部署和配置 Ingress 规则来管理传入的 HTTP 请求。
创建 Deployment 首先，部署一个示例 HTTP 服务器，它将成为我们请求的目标。部署中包含三个部署，分别为 webapp1， webapp2， webapp3，每个部署都有一个服务。
deployment.yaml
apiVersion:apps/v1kind:Deploymentmetadata:name:webapp1spec:replicas:1selector:matchLabels:app:webapp1template:metadata:labels:app:webapp1spec:containers:- name:webapp1image:katacoda/docker-http-server:latestports:- containerPort:80---apiVersion:apps/v1kind:Deploymentmetadata:name:webapp2spec:replicas:1selector:matchLabels:app:webapp2template:metadata:labels:app:webapp2spec:containers:- name:webapp2image:katacoda/docker-http-server:latestports:- containerPort:80---apiVersion:apps/v1kind:Deploymentmetadata:name:webapp3spec:replicas:1selector:matchLabels:app:webapp3template:metadata:labels:app:webapp3spec:containers:- name:webapp3image:katacoda/docker-http-server:latestports:- containerPort:80---apiVersion:v1kind:Servicemetadata:name:webapp1-svclabels:app:webapp1spec:ports:- port:80selector:app:webapp1---apiVersion:v1kind:Servicemetadata:name:webapp2-svclabels:app:webapp2spec:ports:- port:80selector:app:webapp2---apiVersion:v1kind:Servicemetadata:name:webapp3-svclabels:app:webapp3spec:ports:- port:80selector:app:webapp3任务 使用 kubectl apply -f deployment.yaml 命令部署 YAML 定义。
controlplane $ kubectl apply -f deployment.yaml deployment.apps/webapp1 created deployment.apps/webapp2 created deployment.apps/webapp3 created service/webapp1-svc created service/webapp2-svc created service/webapp3-svc created 可以用 kubectl get deployment 查看状态。</description></item><item><title>Kubernetes初探（六）</title><link>https://www.catfish.top/p/k8s-basic-6/</link><pubDate>Tue, 20 Jul 2021 13:36:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-6/</guid><description>Katacoda在线课：Networking Introduction
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
Kubernetes 具有先进的网络功能，允许 Pod 和 Service 在集群网络内部和外部进行通信。
在此场景中，您将学习以下类型的 Kubernetes Service。
Cluster IP Target Ports NodePort External IPs Load Balancer Kubernetes 服务是一个抽象，它定义了如何访问一组 Pod 的策略和方法。可以通过 Service 访问基于标签选择器的 Pod 集合。
Cluster IP Cluster IP 是创建 Kubernetes 服务时的默认方法。该服务被分配了一个内部 IP，其他组件可以使用它来访问 Pod。
Service 能够通过单个 IP 地址在多个 Pod 之间进行负载平衡。
通过 kubectl apply -f clusterip.yaml 命令部署服务。
在 cat clusterip.yaml 可以查看相关定义。
clusterip.yaml
apiVersion:v1kind:Servicemetadata:name:webapp1-clusterip-svclabels:app:webapp1-clusteripspec:ports:- port:80selector:app:webapp1-clusterip---apiVersion:extensions/v1beta1kind:Deploymentmetadata:name:webapp1-clusterip-deploymentspec:replicas:2template:metadata:labels:app:webapp1-clusteripspec:containers:- name:webapp1-clusterip-podimage:katacoda/docker-http-server:latestports:- containerPort:80---controlplane $ kubectl apply -f clusterip.</description></item><item><title>Kubernetes初探（五）</title><link>https://www.catfish.top/p/k8s-basic-5/</link><pubDate>Tue, 20 Jul 2021 13:18:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-5/</guid><description>Katacoda在线课：Deploy Guestbook Web App Example
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
本场景说明了如何使用 Kubernetes 和 Docker 启动简单的多层 Web 应用。留言簿示例应用程序通过调用* JavaScript API* 将访客的笔记存储在 *Redis* 中。 *Redis* 包含一个 master（用于存储）和一组 *slave* 复制集。
核心概念 在此场景中将涵盖以下核心概念。这些是理解 Kubernetes 的基础。
Pods Replication Controllers Services NodePorts 启动 Kubernetes 首先，我们需要一个正在运行的 Kubernetes 集群。详细信息在 Launch Kubernetes cluster
任务 使用初始化程序脚本启动单节点集群。初始化脚本将启动 API、Master、Proxy 和 DNS Discovery。 Web App 使用 DNS Discovery 来查找 Redis slave 来存储数据。
launch.sh 健康检查 使用 kubectl cluster-info 和 kubectl get nodes命令来检查部署的集群的节点健康信息。</description></item><item><title>Kubernetes初探（四）</title><link>https://www.catfish.top/p/k8s-basic-4/</link><pubDate>Tue, 20 Jul 2021 11:39:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-4/</guid><description>Katacoda在线课：Deploy Containers Using YAML
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
在此场景中，您将学习如何使用 Kubectl 创建和启动 Deployment、Replication Controller，并通过编写 yaml 定义使用服务开暴露它们。
YAML 定义了计划部署的 Kubernetes 对象。可以以更新对象并将其重新部署到集群的方式来更改配置。
创建 Deployment Deployment 对象是最常见的 Kubernetes 对象之一。Deployment 对象定义了所需的容器规范，以及 Kubernetes 其他部分用来发现和连接到应用程序的名称和标签。
任务 将以下定义复制到编辑器的YAML文件中。该 YAML 定义了如何使用在端口 80 上运行的应用，该应用使用 Docker 映像 katacoda/docker-http-server ，启动名为 webapp1 。
deployment.yaml
apiVersion:apps/v1kind:Deploymentmetadata:name:webapp1spec:replicas:1selector:matchLabels:app:webapp1template:metadata:labels:app:webapp1spec:containers:- name:webapp1image:katacoda/docker-http-server:latestports:- containerPort:80使用 kubectl create -f deployment.yaml 命令向集群部署。
$ kubectl create -f deployment.yaml deployment.apps/webapp1 created 由于它是一个 Deployment 对象，因此可以通过 kubectl get deployment 获取所有已部署的 Deployment 对象的列表。
$ kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE webapp1 1/1 1 1 10s 可以使用 kubectl describe deployment webapp1 输出单个部署的详细信息。</description></item><item><title>Kubernetes初探（三）</title><link>https://www.catfish.top/p/k8s-basic-3/</link><pubDate>Tue, 20 Jul 2021 11:27:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-3/</guid><description>Katacoda在线课：Deploy Containers Using Kubectl
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
在此场景中，将学习如何使用 Kubectl 创建和启动 Deployment 和 Replication Controllers 并通过 Services 对外暴露接口。本场景中无需编写 yaml 定义，便可以快速将容器启动到集群上。
启动集群 首先，我们需要启动一个 Kubernetes 集群。
执行以下命令启动集群并下载 Kubectl CLI。
$ minikube start --wait=false * minikube v1.8.1 on Ubuntu 18.04 * Using the none driver based on user configuration * Running on localhost (CPUs=2, Memory=2460MB, Disk=145651MB) ... * OS release is Ubuntu 18.04.4 LTS * Preparing Kubernetes v1.17.3 on Docker 19.03.6 .</description></item><item><title>Kubernetes初探（二）</title><link>https://www.catfish.top/p/k8s-basic-2/</link><pubDate>Tue, 20 Jul 2021 11:05:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-2/</guid><description>Katacoda在线课：Launch a multi-node cluster using Kubeadm
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
在此场景中，您将学习如何使用 Kubeadm 启动 Kubernetes 集群。
Kubeadm 解决了TLS 加密配置、 Kubernetes 核心组件部署和额外节点集群加入的问题。启动的集群通过 RBAC 等机制开箱即用。
关于 Kubeadm 的更多信息可以参考： https://github.com/kubernetes/kubeadm
初始化 Master Kubeadm 已经安装在节点上。软件包适用于 Ubuntu 16.04+、CentOS 7 或 HypriotOS v1.0.1+。
初始化集群的第一步是启动 Master节点 。 Master节点 负责运行控制平面组件、etcd 和 API 服务器。客户端能够与 API 通信，能够完成工作负载的调度和集群状态的管理。
任务 下面的命令将使用已知的 Token 简化初始化集群的步骤。
controlplane $ kubeadm init --token=102952.1a7dd4cc8d1f4cc5 --kubernetes-version $(kubeadm version -o short) [init] Using Kubernetes version: v1.14.0 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using &amp;#39;kubeadm config images pull&amp;#39; [kubelet-start] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.</description></item><item><title>Kubernetes初探（一）</title><link>https://www.catfish.top/p/k8s-basic-1/</link><pubDate>Tue, 20 Jul 2021 10:21:00 +0800</pubDate><guid>https://www.catfish.top/p/k8s-basic-1/</guid><description>Katacoda在线课：Launch A Single Node Cluster
本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。
Minikube 是一个可以轻松在本地运行 Kubernetes 的工具。 Minikube 是一个在本地上计算机的虚拟机内运行一个单节点 Kubernetes 集群，便于用户能够完成日常开发工作，同时也能够让新用户快速了解 Kubernetes 。
详情见： https://github.com/kubernetes/minikube
步骤 1 - 启动 Minikube Minikube 已经安装并配置到环境中。通过运行 minikube version 命令检查它是否已正确安装。
$ minikube version minikube version: v1.8.1 commit: cbda04cf6bbe65e987ae52bb393c10099ab62014 通过运行 minikube start 命令启动集群。
$ minikube start --wait=false * minikube v1.8.1 on Ubuntu 18.04 * Using the none driver based on user configuration * Running on localhost (CPUs=2, Memory=2460MB, Disk=145651MB) .</description></item><item><title>Katacoda 在线学习神器</title><link>https://www.catfish.top/p/katacoda/</link><pubDate>Mon, 19 Jul 2021 17:57:00 +0800</pubDate><guid>https://www.catfish.top/p/katacoda/</guid><description>介绍 Katacoda 是一个面向软件工程师的交互式学习和培训平台，可在浏览器中使用真实环境学习和测试新技术，帮助开发人员学习，并掌握最佳实践。
Katacoda 的目标是消除新技术和技能的障碍。
Katacoda 提供了一个平台来构建实时交互式演示和培训环境。运行环境可以根据应用要求进行定制。分步指导路径旨在确保用户以最佳方式学习。用户可以根据设计好的引导步骤，通过浏览器上的终端界面操作一套完整的环境，一步步的学习和实践。Katacoda 的出现很好的解决了这些问题。课程设计者可以定制应用程序所需环境，并设计循序渐进的指导路径，旨在确保用户以最佳方式学习。
Katacoda 同样也是Kubernetes官网的学习工具，能够快速帮助开发者掌握K8s知识与应用，同时能够节省大量搭建部署环境的时间与精力，能够让开发者专注于学习掌握K8s。
Playground功能更是为开发者带来一种新的开发体验。借助于Katacoda平台，能够快速构建满足应用要求的各类环境，开发者能够在这之中，专注于完成创造、验证等工作。
使用体验 课程 Playground 中文翻译-目录 Kubernetes Basic 原文：https://www.katacoda.com/courses/kubernetes
Launch A Single Node Cluster 原文：https://www.katacoda.com/courses/kubernetes/launch-single-node-cluster</description></item><item><title>MIT 6.824 分布式系统初探（一）</title><link>https://www.catfish.top/p/mit6.824-1/</link><pubDate>Thu, 07 Sep 2017 01:21:00 +0800</pubDate><guid>https://www.catfish.top/p/mit6.824-1/</guid><description>概述 Google工程师Jeffrey Dean 和 Sanjay Ghemawat在2004年发表了一篇论文MapReduce: Simplified Data Processing on Large Clusters，MapReduce作为大规模数据处理的需求下孕育而生的产物，被创造的初衷是为了解决Google公司内部搜索引擎中大规模数据的并行化处理。
引用维基百科中对MapReduce的介绍：
MapReduce是Google提出的一个软件架构，用于大规模数据集（大于1TB）的并行运算。
概念“Map（映射）”和“Reduce（归纳）”，及他们的主要思想，都是从函数式编程语言借来的，还有从矢量编程语言借来的特性。当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归纳）函数，用来保证所有映射的键值对中的每一个共享相同的键组。
本系列将根据MIT6.824课程进行学习 MapReduce
简单看来，MapReduce的架构正如其名，分为Map和Reduce两部分。
MapReduce Overview
作为一个计算框架，其最大的核心便在于计算二字，以往处理计算的模式为单机运行，在大数据的情况下只能使用具有更强算力的计算机来完成计算工作，而算力的提升是需要花费极大的成本，这样在成本上是极为不划算的。在这一背景下MapReduce孕育而生，有个这样一个框架，就可以将数台不同算力的计算机组成一个集群，和适度的调度下并行计算提高效率降低成本。
根据上图，MapReduce中存在3中角色，Master，Worker（Map），Worker(Reduce）,Master负责Map，Reduce两层的调度管理,Worker(Map)负责进行Map操作，Worker（Reduce）负责进行Reduce操作
现在以该课程lab1为例来进行细致的学习，整套课程将由Go语言来实现。 lab1主要是对MapReduce模型进行初步的学习，实现一个本机的MapReduce模型，完成对多个文件的词频统计。
示例程序流程 入口由上层程序控制，这个地方从master调度开始，预先定义Reduce任务个数m，再根据文本文件输入数量n。
master将n传递给doMap也就是Map调度层，告诉Map调度层执行n次Map计算，每个Map计算层对应输入各个文本文件的数据。
Map调度层将输出m*n个文件作为Map和Reduce的中间数据传递媒介，举例假设现在m为2、n为3，输出文件mid-0-0 mid-0-1 mid-1-0 mid-1-1 mid-2-0 mid-2-1这六个文件,其中mid-0-0 mid-0-1为第一个文本Map操作后的到的切分开的两个中间数据文件，剩下的以此类推。
在Reduce调度层中便会将这六个文件交由Reduce计算层处理，将件mid-0-0 mid-1-0 mid-2-0交由编号为0的Reduce计算任务处理，显然，编号为1的任务则负责剩下3个文件的规约操作。Reduce调度层中仍然会将每个Reduce计算层任务得到的数据分别存入文件，根据Reduce任务的数量m为2，则文件编号分别为res-0 res-1，这样Map、Reduce两种操作完成，但整个任务还为完成。
Merge操作则是最后一个步骤通常由master来完成，通过merge操作将上述的res-0 res-1合并，将所有结果存入到一个文件中，这样，整个MapReduce实现的多文本词频统计程序执行完毕。
数据结构 type KeyValue struct { Key string Value string } 实现 Master调度 master.go
func (mr *Master) run(jobName string, files []string, nreduce int, schedule func(phase jobPhase), finish func(), ) { mr.</description></item><item><title>Blog 第一帖 - 字符坑 BOM</title><link>https://www.catfish.top/p/bom/</link><pubDate>Wed, 18 May 2016 00:36:00 +0800</pubDate><guid>https://www.catfish.top/p/bom/</guid><description>字符编码 字集码是把字符集中的字符编码为指定集合中某一对象（例如：比特模式、自然数序列、8位组或者电脉冲），以便文本在计算机中存储和通过通信网络的传递。
常见的例子包括将拉丁字母表编码成摩斯电码和ASCII。其中，ASCII将字母、数字和其它符号编号，并用7比特的二进制来表示这个整数。通常会额外使用一个扩充的比特，以便于以1个字节的方式存储。 常见的字符编码有： ASCII、UTF-8、Unicode、GBK等
详见WikiPedia
ASCII ASCII ( A merican S tandard C ode for I nformation I nterchange) 即美国信息交换标准代码。
ASCII第一次以规范标准的型态发表是在1967年，最后一次更新则是在1986年，至今为止共定义了128个字符；其中33个字符无法显示（一些终端提供了扩展，使得这些字符可显示为诸如笑脸、扑克牌花式等8-bit符号），且这33个字符多数都已是陈废的控制字符。控制字符的用途主要是用来操控已经处理过的文字。在33个字符之外的是95个可显示的字符，包含用键盘敲下空白键所产生的空白字符也算1个可显示字符（显示为空白）。
ASCII的局限在于只能显示26个基本拉丁字母、阿拉伯数目字和英式标点符号，因此只能用于显示现代美国英语（而且在处理英语当中的外来词如naïve、café、élite等等时，所有重音符号都不得不去掉，即使这样做会违反拼写规则）。而EASCII虽然解决了部分西欧语言的显示问题，但对更多其他语言依然无能为力。因此现在的软件系统大多采用Unicode。
详见WikiPedia
Unicode Unicode 是为了解决传统的字符编码方案的局限而产生的，例如ISO 8859-1所定义的字符虽然在不同的国家中广泛地使用，可是在不同国家间却经常出现不兼容的情况。
很多传统的编码方式都有一个共同的问题，即容许电脑处理双语环境（通常使用拉丁字母以及其本地语言），但却无法同时支持多语言环境（指可同时处理多种语言混合的情况）。
目前，几乎所有电脑系统都支持基本拉丁字母，并各自支持不同的其他编码方式。Unicode为了和它们相互兼容，其首256字符保留给ISO 8859-1所定义的字符，使既有的西欧语系文字的转换不需特别考量；并且把大量相同的字符重复编到不同的字符码中去，使得旧有纷杂的编码方式得以和Unicode编码间互相直接转换，而不会丢失任何信息。举例来说，全角格式区块包含了主要的拉丁字母的全角格式，在中文、日文、以及韩文字形当中，这些字符以全角的方式来呈现，而不以常见的半角形式显示，这对竖排文字和等宽排列文字有重要作用。
详见WikiPedia
UTF-8 UTF-8 （8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。
它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。因此，它逐渐成为电子邮件、网页及其他存储或发送文字的应用中，优先采用的编码。
UTF-8 现已经作为通用的字符编码，应用于各中网页编码，数据编码，数据库字符编码等。编码的统一能够写出的程序或网页在中文环境下大大减少乱码的出现。dddddddddddddddddd
详见WikiPedia
GBK 汉字内码扩展规范 ，称GBK，全名为《汉字内码扩展规范(GBK)》1.0版，由中华人民共和国全国信息技术标准化技术委员会1995年12月1日制订，国家技术监督局标准化司和电子工业部科技与质量监督司1995年12月15日联合以《技术标函[1995]229号》文件的形式公布。
GBK的K为汉语拼音Kuo Zhan（扩展）中“扩”字的声母。英文全称Chinese Internal Code Extension Specification。
GBK 只为“技术规范指导性文件”，不属于国家标准。国家质量技术监督局于2000年3月17日推出了GB 18030-2000标准，以取代GBK。
BOM ( Byte Order Mark ) 这个才是重点，BOM头。</description></item></channel></rss>